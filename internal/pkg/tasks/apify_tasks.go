package tasks

import (
	"context"
	"encoding/json"
	"fmt"
	"math"
	"strings"
	"time"

	"amazonpilot/internal/pkg/apify"
	"amazonpilot/internal/pkg/database"
	"amazonpilot/internal/pkg/logger"
	"amazonpilot/internal/pkg/models"

	"github.com/hibiken/asynq"
	"github.com/redis/go-redis/v9"
	"gorm.io/gorm"
)

const (
	TypeRefreshProductData = "refresh_product_data"
)

type RefreshProductDataPayload struct {
	ProductID   string `json:"product_id"`
	TrackedID   string `json:"tracked_id"`
	ASIN        string `json:"asin"`
	UserID      string `json:"user_id"`
	RequestedAt string `json:"requested_at"`
}

type ApifyTaskProcessor struct {
	db          *gorm.DB
	redisClient *redis.Client
	apifyClient *apify.Client
	asynqClient *asynq.Client
	logger      *logger.ServiceLogger
}

func NewApifyTaskProcessor(dsn string, apifyToken string, redisAddr string) *ApifyTaskProcessor {
	// è¿æ¥æ•°æ®åº“
	db, err := database.NewConnectionWithDSN(dsn, &database.Config{
		MaxIdleConns:    10,
		MaxOpenConns:    100,
		ConnMaxLifetime: 3600,
	})
	if err != nil {
		panic("Failed to connect to database: " + err.Error())
	}

	// åˆå§‹åŒ–Apifyå®¢æˆ·ç«¯
	apifyClient := apify.NewClient(apifyToken)

	// åˆå§‹åŒ–Asynqå®¢æˆ·ç«¯ (ç”¨äºå‘é€å¼‚å¸¸æ£€æµ‹æ¶ˆæ¯)
	redisOpt := asynq.RedisClientOpt{
		Addr: redisAddr,
		DB:   0,
	}
	asynqClient := asynq.NewClient(redisOpt)

	serviceLogger := logger.NewServiceLogger("apify-worker")

	return &ApifyTaskProcessor{
		db:          db,
		apifyClient: apifyClient,
		asynqClient: asynqClient,
		logger:      serviceLogger,
	}
}

// HandleRefreshProductData å¤„ç†äº§å“æ•°æ®åˆ·æ–°ä»»åŠ¡
func (processor *ApifyTaskProcessor) HandleRefreshProductData(ctx context.Context, t *asynq.Task) error {
	var payload RefreshProductDataPayload
	if err := json.Unmarshal(t.Payload(), &payload); err != nil {
		return fmt.Errorf("failed to unmarshal payload: %w", err)
	}

	processor.logger.LogBusinessOperation(ctx, "refresh_task_started", "apify_worker", payload.ProductID, "processing",
		"asin", payload.ASIN,
		"task_id", t.Type(),
	)

	// ç›´æ¥ä½¿ç”¨apify.Clientè°ƒç”¨äº§å“è¯¦æƒ…actor
	productData, err := processor.apifyClient.FetchProductData(ctx, []string{payload.ASIN}, 60*time.Second)
	if err != nil {
		processor.logger.LogBusinessOperation(ctx, "refresh_task_failed", "apify_worker", payload.ProductID, "failed",
			"asin", payload.ASIN,
			"error", err.Error(),
		)
		return fmt.Errorf("failed to fetch product data from Apify: %w", err)
	}

	if len(productData) == 0 {
		processor.logger.LogBusinessOperation(ctx, "refresh_task_no_data", "apify_worker", payload.ProductID, "failed",
			"asin", payload.ASIN,
		)
		return fmt.Errorf("no product data returned from Apify for ASIN: %s", payload.ASIN)
	}

	// ç›´æ¥ä½¿ç”¨è¿”å›çš„æ•°æ®ï¼Œå› ä¸ºapify clientå·²ç»è§£æè¿‡äº†
	data := productData[0]

	// è®°å½•è·å–åˆ°çš„æ•°æ®
	processor.logger.LogBusinessOperation(ctx, "apify_data_received", "apify_worker", payload.ProductID, "success",
		"asin", data.ASIN,
		"title", data.Title,
		"price", data.Price,
		"rating", data.Rating,
		"review_count", data.ReviewCount,
		"bsr", data.BSR,
	)
	now := time.Now()

	// å¼€å§‹æ•°æ®åº“äº‹åŠ¡
	tx := processor.db.Begin()
	defer func() {
		if r := recover(); r != nil {
			tx.Rollback()
		}
	}()

	// æ›´æ–°äº§å“åŸºç¡€ä¿¡æ¯ï¼ŒåŒ…å«å®Œæ•´çš„Apifyæ•°æ®æ˜ å°„
	updates := map[string]interface{}{
		"title":           data.Title,
		"brand":           data.Brand,
		"category":        data.Category,
		"description":     data.Description,
		"last_updated_at": now,
	}

	// æ˜ å°„bullet points (Apifyçš„features -> æ•°æ®åº“çš„bullet_points)
	if len(data.BulletPoints) > 0 {
		bulletPointsJSON, _ := json.Marshal(data.BulletPoints)
		updates["bullet_points"] = bulletPointsJSON
	}

	// æ˜ å°„å›¾ç‰‡URLs
	if len(data.Images) > 0 {
		imagesJSON, _ := json.Marshal(data.Images)
		updates["images"] = imagesJSON
	}

	if err := tx.Table("products").Where("id = ?", payload.ProductID).Updates(updates).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to update product: %w", err)
	}

	// ä¿å­˜ä»·æ ¼å†å²
	priceHistory := models.PriceHistory{
		ProductID:   payload.ProductID,
		Price:       data.Price,
		Currency:    data.Currency,
		BuyBoxPrice: &data.Price,
		RecordedAt:  now,
		DataSource:  "apify",
	}

	if err := tx.Create(&priceHistory).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to save price history: %w", err)
	}

	// ä¿å­˜æ’åå†å²
	rankingHistory := models.RankingHistory{
		ProductID:   payload.ProductID,
		Category:    data.BSRCategory,
		BSRRank:     &data.BSR,
		Rating:      &data.Rating,
		ReviewCount: data.ReviewCount,
		RecordedAt:  now,
		DataSource:  "apify",
	}

	if err := tx.Create(&rankingHistory).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to save ranking history: %w", err)
	}

	// è·å–å†å²æ•°æ®ç”¨äºå¼‚å¸¸æ£€æµ‹ (æ’é™¤åˆšæ’å…¥çš„è®°å½•)
	var lastPrice models.PriceHistory
	processor.db.Where("product_id = ? AND id != ?", payload.ProductID, priceHistory.ID).
		Order("recorded_at DESC").
		First(&lastPrice)

	var lastRanking models.RankingHistory
	processor.db.Where("product_id = ? AND id != ?", payload.ProductID, rankingHistory.ID).
		Order("recorded_at DESC").
		First(&lastRanking)

	// æ›´æ–°è¿½è¸ªè®°å½•çš„æ£€æŸ¥æ—¶é—´ (åœ¨äº‹åŠ¡æäº¤å‰)
	if err := tx.Table("tracked_products").Where("id = ?", payload.TrackedID).Updates(map[string]interface{}{
		"last_checked_at": now,
	}).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to update tracked product: %w", err)
	}

	// æäº¤äº‹åŠ¡
	if err := tx.Commit().Error; err != nil {
		return fmt.Errorf("failed to commit transaction: %w", err)
	}

	// ğŸš€ æ•°æ®ä¿å­˜æˆåŠŸï¼Œç°åœ¨è¿›è¡Œå¼‚å¸¸æ£€æµ‹
	processor.detectAndRecordAnomalies(ctx, payload, data, lastPrice, lastRanking, priceHistory.ID, rankingHistory.ID, now)

	// æ¸…ç†ç›¸å…³ç¼“å­˜ï¼Œç¡®ä¿å‰ç«¯è·å–æœ€æ–°æ•°æ®
	processor.invalidateProductCache(ctx, payload.ASIN, payload.ProductID, payload.UserID)

	processor.logger.LogBusinessOperation(ctx, "refresh_task_completed", "apify_worker", payload.ProductID, "success",
		"asin", payload.ASIN,
		"price", data.Price,
		"bsr", data.BSR,
		"rating", data.Rating,
		"review_count", data.ReviewCount,
	)

	return nil
}

// detectAndRecordAnomalies æ£€æµ‹å¹¶è®°å½•å¼‚å¸¸å˜åŒ– (requirements: ä»·æ ¼å˜åŠ¨>10%, BSRå˜åŠ¨>30%)
func (p *ApifyTaskProcessor) detectAndRecordAnomalies(ctx context.Context, payload RefreshProductDataPayload, newData apify.ProductData, lastPrice models.PriceHistory, lastRanking models.RankingHistory, newPriceID, newRankingID string, now time.Time) {

	// è·å–ç”¨æˆ·è®¾ç½®çš„é˜ˆå€¼
	var trackedProduct models.TrackedProduct
	if err := p.db.Where("id = ?", payload.TrackedID).First(&trackedProduct).Error; err != nil {
		p.logger.LogBusinessOperation(ctx, "anomaly_detection_failed", "apify_worker", payload.ProductID, "failed",
			"error", "failed to get tracking thresholds",
		)
		return
	}

	anomalyEvents := []models.AnomalyEvent{}

	// 1. ä»·æ ¼å¼‚å¸¸æ£€æµ‹ (questions.mdè¦æ±‚: >10%)
	if lastPrice.Price > 0 && newData.Price > 0 {
		priceChangePercentage := math.Abs((newData.Price-lastPrice.Price)/lastPrice.Price) * 100
		threshold := trackedProduct.PriceChangeThreshold
		if threshold == 0 {
			threshold = 10.0 // é»˜è®¤é˜ˆå€¼
		}

		if priceChangePercentage > threshold {
			thresholdPtr := &threshold
			severity := getSeverityForPriceChange(priceChangePercentage)
			anomalyEvent := models.AnomalyEvent{
				ProductID:        payload.ProductID,
				ASIN:             payload.ASIN,
				EventType:        "price_change",
				OldValue:         &lastPrice.Price,
				NewValue:         &newData.Price,
				ChangePercentage: &priceChangePercentage,
				Threshold:        thresholdPtr,
				Severity:         severity,
				CreatedAt:        now,
			}
			anomalyEvents = append(anomalyEvents, anomalyEvent)
		}
	}

	// 2. BSRå¼‚å¸¸æ£€æµ‹ (questions.mdè¦æ±‚: >30%)
	if lastRanking.BSRRank != nil && *lastRanking.BSRRank > 0 && newData.BSR > 0 {
		oldBSR := float64(*lastRanking.BSRRank)
		newBSR := float64(newData.BSR)
		bsrChangePercentage := math.Abs((newBSR-oldBSR)/oldBSR) * 100
		threshold := trackedProduct.BSRChangeThreshold
		if threshold == 0 {
			threshold = 30.0 // é»˜è®¤é˜ˆå€¼
		}

		if bsrChangePercentage > threshold {
			thresholdPtr := &threshold
			severity := getSeverityForBSRChange(bsrChangePercentage)
			anomalyEvent := models.AnomalyEvent{
				ProductID:        payload.ProductID,
				ASIN:             payload.ASIN,
				EventType:        "bsr_change",
				OldValue:         &oldBSR,
				NewValue:         &newBSR,
				ChangePercentage: &bsrChangePercentage,
				Threshold:        thresholdPtr,
				Severity:         severity,
				CreatedAt:        now,
			}
			anomalyEvents = append(anomalyEvents, anomalyEvent)
		}
	}

	// 3. è¯„åˆ†å˜åŒ–æ£€æµ‹ (questions.mdè¦æ±‚: è©•åˆ†èˆ‡è©•è«–æ•¸è®ŠåŒ–)
	if lastRanking.Rating != nil && *lastRanking.Rating > 0 && newData.Rating > 0 {
		oldRating := *lastRanking.Rating
		newRating := newData.Rating
		ratingChangePercentage := math.Abs((newRating-oldRating)/oldRating) * 100

		// è¯„åˆ†å˜åŒ–é˜ˆå€¼å¯ä»¥è®¾ä¸º5%ï¼ˆæ¯”è¾ƒæ•æ„Ÿï¼‰
		ratingThreshold := 5.0
		if ratingChangePercentage > ratingThreshold {
			thresholdPtr := &ratingThreshold
			severity := "info" // è¯„åˆ†å˜åŒ–é€šå¸¸æ˜¯infoçº§åˆ«
			if ratingChangePercentage > 20 {
				severity = "warning"
			}

			anomalyEvent := models.AnomalyEvent{
				ProductID:        payload.ProductID,
				ASIN:             payload.ASIN,
				EventType:        "rating_change",
				OldValue:         &oldRating,
				NewValue:         &newRating,
				ChangePercentage: &ratingChangePercentage,
				Threshold:        thresholdPtr,
				Severity:         severity,
				CreatedAt:        now,
			}
			anomalyEvents = append(anomalyEvents, anomalyEvent)
		}
	}

	// 4. è¯„è®ºæ•°å˜åŒ–æ£€æµ‹ (questions.mdè¦æ±‚: è©•åˆ†èˆ‡è©•è«–æ•¸è®ŠåŒ–)
	if lastRanking.ReviewCount > 0 && newData.ReviewCount > 0 {
		oldReviewCount := float64(lastRanking.ReviewCount)
		newReviewCount := float64(newData.ReviewCount)
		reviewChangePercentage := math.Abs((newReviewCount-oldReviewCount)/oldReviewCount) * 100

		// è¯„è®ºæ•°å˜åŒ–é˜ˆå€¼è®¾ä¸º20%
		reviewThreshold := 20.0
		if reviewChangePercentage > reviewThreshold {
			thresholdPtr := &reviewThreshold
			severity := "info"
			if reviewChangePercentage > 50 {
				severity = "warning"
			}

			anomalyEvent := models.AnomalyEvent{
				ProductID:        payload.ProductID,
				ASIN:             payload.ASIN,
				EventType:        "review_count_change",
				OldValue:         &oldReviewCount,
				NewValue:         &newReviewCount,
				ChangePercentage: &reviewChangePercentage,
				Threshold:        thresholdPtr,
				Severity:         severity,
				CreatedAt:        now,
			}
			anomalyEvents = append(anomalyEvents, anomalyEvent)
		}
	}

	// 3. æ‰¹é‡ä¿å­˜å¼‚å¸¸äº‹ä»¶
	if len(anomalyEvents) > 0 {
		if err := p.db.Create(&anomalyEvents).Error; err != nil {
			p.logger.LogBusinessOperation(ctx, "anomaly_record_failed", "apify_worker", payload.ProductID, "failed",
				"error", err.Error(),
				"events_count", len(anomalyEvents),
			)
		} else {
			p.logger.LogBusinessOperation(ctx, "anomaly_detected", "apify_worker", payload.ProductID, "success",
				"asin", payload.ASIN,
				"events_count", len(anomalyEvents),
				"events", getEventSummary(anomalyEvents),
			)
		}
	}
}

// getSeverityForPriceChange æ ¹æ®ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”ç¡®å®šä¸¥é‡ç¨‹åº¦
func getSeverityForPriceChange(percentage float64) string {
	if percentage >= 20 {
		return "critical"
	} else if percentage >= 10 {
		return "warning"
	}
	return "info"
}

// getSeverityForBSRChange æ ¹æ®BSRå˜åŒ–ç™¾åˆ†æ¯”ç¡®å®šä¸¥é‡ç¨‹åº¦
func getSeverityForBSRChange(percentage float64) string {
	if percentage >= 50 {
		return "critical"
	} else if percentage >= 30 {
		return "warning"
	}
	return "info"
}

// getEventSummary è·å–äº‹ä»¶æ‘˜è¦ç”¨äºæ—¥å¿—
func getEventSummary(events []models.AnomalyEvent) string {
	summary := make([]string, len(events))
	for i, event := range events {
		summary[i] = fmt.Sprintf("%s:%.1f%%", event.EventType, *event.ChangePercentage)
	}
	return strings.Join(summary, ",")
}

// invalidateProductCache æ¸…ç†äº§å“ç›¸å…³ç¼“å­˜ (ç®€åŒ–ç‰ˆæœ¬)
func (p *ApifyTaskProcessor) invalidateProductCache(ctx context.Context, asin, productID, userID string) {
	// ä½¿ç”¨å·²é…ç½®çš„Rediså®¢æˆ·ç«¯è¿›è¡Œç¼“å­˜æ¸…ç†
	defer p.redisClient.Close()

	// æ¸…ç†äº§å“åŸºæœ¬ä¿¡æ¯ç¼“å­˜
	productCacheKey := fmt.Sprintf("amazon_pilot:product:%s", asin)
	p.redisClient.Del(ctx, productCacheKey)

	// æ¸…ç†ç”¨æˆ·è¿½è¸ªäº§å“åˆ—è¡¨ç¼“å­˜
	trackedCacheKey := fmt.Sprintf("amazon_pilot:tracked:%s", userID)
	p.redisClient.Del(ctx, trackedCacheKey)

	// æ¸…ç†æœ€æ–°ä»·æ ¼æ•°æ®ç¼“å­˜
	priceCacheKey := fmt.Sprintf("amazon_pilot:price:%s:latest", productID)
	p.redisClient.Del(ctx, priceCacheKey)

	p.logger.LogBusinessOperation(ctx, "cache_invalidated", "apify_worker", productID, "success",
		"asin", asin,
		"user_id", userID,
	)
}
