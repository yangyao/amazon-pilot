package tasks

import (
	"context"
	"encoding/json"
	"fmt"
	"math"
	"os"
	"strings"
	"time"

	"amazonpilot/internal/pkg/apify"
	"amazonpilot/internal/pkg/cache"
	"amazonpilot/internal/pkg/database"
	"amazonpilot/internal/pkg/llm"
	"amazonpilot/internal/pkg/logger"
	"amazonpilot/internal/pkg/models"

	"github.com/hibiken/asynq"
	"github.com/redis/go-redis/v9"
	"gorm.io/gorm"
)

const (
	TypeRefreshProductData = "refresh_product_data"
	TypeGenerateReport     = "generate_competitor_report"
)

type RefreshProductDataPayload struct {
	ProductID   string `json:"product_id"`
	TrackedID   string `json:"tracked_id"`
	ASIN        string `json:"asin"`
	UserID      string `json:"user_id"`
	RequestedAt string `json:"requested_at"`
}

type GenerateReportPayload struct {
	AnalysisID  string `json:"analysis_id"`
	UserID      string `json:"user_id"`
	TaskID      string `json:"task_id"`
	Force       bool   `json:"force"`
	RequestedAt string `json:"requested_at"`
}

type ApifyTaskProcessor struct {
	db          *gorm.DB
	redisClient *redis.Client
	apifyClient *apify.Client
	asynqClient *asynq.Client
	logger      *logger.ServiceLogger
}

func NewApifyTaskProcessor(dsn string, apifyToken string, redisAddr string) *ApifyTaskProcessor {
	// è¿æ¥æ•°æ®åº“
	db, err := database.NewConnectionWithDSN(dsn, &database.Config{
		MaxIdleConns:    10,
		MaxOpenConns:    100,
		ConnMaxLifetime: 3600,
	})
	if err != nil {
		panic("Failed to connect to database: " + err.Error())
	}

	// åˆå§‹åŒ–Apifyå®¢æˆ·ç«¯
	apifyClient := apify.NewClient(apifyToken)

	// åˆå§‹åŒ–Asynqå®¢æˆ·ç«¯ (ç”¨äºå‘é€å¼‚å¸¸æ£€æµ‹æ¶ˆæ¯)
	redisOpt := asynq.RedisClientOpt{
		Addr: redisAddr,
		DB:   0,
	}
	asynqClient := asynq.NewClient(redisOpt)

	serviceLogger := logger.NewServiceLogger("apify-worker")

	return &ApifyTaskProcessor{
		db:          db,
		apifyClient: apifyClient,
		asynqClient: asynqClient,
		logger:      serviceLogger,
	}
}

// HandleRefreshProductData å¤„ç†äº§å“æ•°æ®åˆ·æ–°ä»»åŠ¡
func (processor *ApifyTaskProcessor) HandleRefreshProductData(ctx context.Context, t *asynq.Task) error {
	var payload RefreshProductDataPayload
	if err := json.Unmarshal(t.Payload(), &payload); err != nil {
		return fmt.Errorf("failed to unmarshal payload: %w", err)
	}

	processor.logger.LogBusinessOperation(ctx, "refresh_task_started", "apify_worker", payload.ProductID, "processing",
		"asin", payload.ASIN,
		"task_id", t.Type(),
	)

	// ç›´æ¥ä½¿ç”¨apify.Clientè°ƒç”¨äº§å“è¯¦æƒ…actor
	productData, err := processor.apifyClient.FetchProductData(ctx, []string{payload.ASIN}, 60*time.Second)
	if err != nil {
		processor.logger.LogBusinessOperation(ctx, "refresh_task_failed", "apify_worker", payload.ProductID, "failed",
			"asin", payload.ASIN,
			"error", err.Error(),
		)
		return fmt.Errorf("failed to fetch product data from Apify: %w", err)
	}

	if len(productData) == 0 {
		processor.logger.LogBusinessOperation(ctx, "refresh_task_no_data", "apify_worker", payload.ProductID, "failed",
			"asin", payload.ASIN,
		)
		return fmt.Errorf("no product data returned from Apify for ASIN: %s", payload.ASIN)
	}

	// ç›´æ¥ä½¿ç”¨è¿”å›çš„æ•°æ®ï¼Œå› ä¸ºapify clientå·²ç»è§£æè¿‡äº†
	data := productData[0]

	// è®°å½•è·å–åˆ°çš„æ•°æ®
	processor.logger.LogBusinessOperation(ctx, "apify_data_received", "apify_worker", payload.ProductID, "success",
		"asin", data.ASIN,
		"title", data.Title,
		"price", data.Price,
		"rating", data.Rating,
		"review_count", data.ReviewCount,
		"bsr", data.BSR,
	)
	now := time.Now()

	// å¼€å§‹æ•°æ®åº“äº‹åŠ¡
	tx := processor.db.Begin()
	defer func() {
		if r := recover(); r != nil {
			tx.Rollback()
		}
	}()

	// ä½¿ç”¨æ ‡å‡†åŒ–çš„æ˜ å°„å‡½æ•°å¤„ç†æ•°æ®
	updates := MapApifyDataToProduct(&data, nil)
	updates["last_updated_at"] = now

	if err := tx.Table("products").Where("id = ?", payload.ProductID).Updates(updates).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to update product: %w", err)
	}

	// ä¿å­˜ä»·æ ¼å†å²
	priceHistory := models.PriceHistory{
		ProductID:   payload.ProductID,
		Price:       data.Price,
		Currency:    data.Currency,
		BuyBoxPrice: data.BuyBoxPrice, // ä½¿ç”¨å®é™…çš„Buy Boxä»·æ ¼ï¼Œå¯èƒ½ä¸ºnil
		RecordedAt:  now,
		DataSource:  "apify",
	}

	if err := tx.Create(&priceHistory).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to save price history: %w", err)
	}

	// ä¿å­˜æ’åå†å²
	rankingHistory := models.RankingHistory{
		ProductID:   payload.ProductID,
		Category:    data.BSRCategory,
		BSRRank:     &data.BSR,
		Rating:      &data.Rating,
		ReviewCount: data.ReviewCount,
		RecordedAt:  now,
		DataSource:  "apify",
	}

	if err := tx.Create(&rankingHistory).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to save ranking history: %w", err)
	}

	// ä¿å­˜è¯„è®ºå†å²
	reviewHistory := models.ReviewHistory{
		ProductID:     payload.ProductID,
		ReviewCount:   data.ReviewCount,
		AverageRating: &data.Rating,
		RecordedAt:    now,
		DataSource:    "apify",
		// æ³¨æ„ï¼šApify æ²¡æœ‰æä¾›è¯¦ç»†çš„æ˜Ÿçº§åˆ†å¸ƒæ•°æ®ï¼Œæ‰€ä»¥å…¶ä»–å­—æ®µä½¿ç”¨é»˜è®¤å€¼
	}

	if err := tx.Create(&reviewHistory).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to save review history: %w", err)
	}

	// ä¿å­˜ BuyBox å†å²
	buyboxHistory := models.BuyBoxHistory{
		ProductID:        payload.ProductID,
		WinnerSeller:     &data.Seller,
		WinnerPrice:      data.BuyBoxPrice, // ä½¿ç”¨å®é™…çš„Buy Boxä»·æ ¼ï¼Œå¯èƒ½ä¸ºnil
		Currency:         data.Currency,
		IsPrime:          data.Prime,
		IsFBA:            (data.FulfilledBy == "Amazon"), // å¦‚æœç”± Amazon é…é€åˆ™è®¤ä¸ºæ˜¯ FBA
		AvailabilityText: &data.Availability,
		RecordedAt:       now,
		DataSource:       "apify",
	}

	if err := tx.Create(&buyboxHistory).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to save buybox history: %w", err)
	}

	// è·å–å†å²æ•°æ®ç”¨äºå¼‚å¸¸æ£€æµ‹ (æ’é™¤åˆšæ’å…¥çš„è®°å½•)
	var lastPrice models.PriceHistory
	processor.db.Where("product_id = ? AND id != ?", payload.ProductID, priceHistory.ID).
		Order("recorded_at DESC").
		First(&lastPrice)

	var lastRanking models.RankingHistory
	processor.db.Where("product_id = ? AND id != ?", payload.ProductID, rankingHistory.ID).
		Order("recorded_at DESC").
		First(&lastRanking)

	var lastReview models.ReviewHistory
	processor.db.Where("product_id = ? AND id != ?", payload.ProductID, reviewHistory.ID).
		Order("recorded_at DESC").
		First(&lastReview)

	var lastBuybox models.BuyBoxHistory
	processor.db.Where("product_id = ? AND id != ?", payload.ProductID, buyboxHistory.ID).
		Order("recorded_at DESC").
		First(&lastBuybox)

	// æ›´æ–°è¿½è¸ªè®°å½•çš„æ£€æŸ¥æ—¶é—´ (åœ¨äº‹åŠ¡æäº¤å‰)
	if err := tx.Table("tracked_products").Where("id = ?", payload.TrackedID).Updates(map[string]interface{}{
		"last_checked_at": now,
	}).Error; err != nil {
		tx.Rollback()
		return fmt.Errorf("failed to update tracked product: %w", err)
	}

	// æäº¤äº‹åŠ¡
	if err := tx.Commit().Error; err != nil {
		return fmt.Errorf("failed to commit transaction: %w", err)
	}

	// ğŸš€ æ•°æ®ä¿å­˜æˆåŠŸï¼Œç°åœ¨è¿›è¡Œå¼‚å¸¸æ£€æµ‹
	processor.detectAndRecordAnomalies(ctx, payload, data, lastPrice, lastRanking, lastReview, lastBuybox, priceHistory.ID, rankingHistory.ID, reviewHistory.ID, buyboxHistory.ID, now)

	// æ¸…ç†ç›¸å…³ç¼“å­˜ï¼Œç¡®ä¿å‰ç«¯è·å–æœ€æ–°æ•°æ®
	processor.invalidateProductCache(ctx, payload.ASIN, payload.ProductID, payload.UserID)

	processor.logger.LogBusinessOperation(ctx, "refresh_task_completed", "apify_worker", payload.ProductID, "success",
		"asin", payload.ASIN,
		"price", data.Price,
		"bsr", data.BSR,
		"rating", data.Rating,
		"review_count", data.ReviewCount,
		"seller", data.Seller,
		"prime", data.Prime,
		"availability", data.Availability,
	)

	return nil
}

// detectAndRecordAnomalies æ£€æµ‹å¹¶è®°å½•å¼‚å¸¸å˜åŒ– (requirements: ä»·æ ¼å˜åŠ¨>10%, BSRå˜åŠ¨>30%)
func (p *ApifyTaskProcessor) detectAndRecordAnomalies(ctx context.Context, payload RefreshProductDataPayload, newData apify.ProductData, lastPrice models.PriceHistory, lastRanking models.RankingHistory, lastReview models.ReviewHistory, lastBuybox models.BuyBoxHistory, newPriceID, newRankingID, newReviewID, newBuyboxID string, now time.Time) {

	// è·å–ç”¨æˆ·è®¾ç½®çš„é˜ˆå€¼
	var trackedProduct models.TrackedProduct
	if err := p.db.Where("id = ?", payload.TrackedID).First(&trackedProduct).Error; err != nil {
		p.logger.LogBusinessOperation(ctx, "anomaly_detection_failed", "apify_worker", payload.ProductID, "failed",
			"error", "failed to get tracking thresholds",
		)
		return
	}

	anomalyEvents := []models.AnomalyEvent{}

	// 1. ä»·æ ¼å¼‚å¸¸æ£€æµ‹ (questions.mdè¦æ±‚: >10%)
	if lastPrice.Price > 0 && newData.Price > 0 {
		priceChangePercentage := math.Abs((newData.Price-lastPrice.Price)/lastPrice.Price) * 100
		threshold := trackedProduct.PriceChangeThreshold
		if threshold == 0 {
			threshold = 10.0 // é»˜è®¤é˜ˆå€¼
		}

		if priceChangePercentage > threshold {
			thresholdPtr := &threshold
			severity := getSeverityForPriceChange(priceChangePercentage)
			anomalyEvent := models.AnomalyEvent{
				ProductID:        payload.ProductID,
				ASIN:             payload.ASIN,
				EventType:        "price_change",
				OldValue:         &lastPrice.Price,
				NewValue:         &newData.Price,
				ChangePercentage: &priceChangePercentage,
				Threshold:        thresholdPtr,
				Severity:         severity,
				CreatedAt:        now,
			}
			anomalyEvents = append(anomalyEvents, anomalyEvent)
		}
	}

	// 2. BSRå¼‚å¸¸æ£€æµ‹ (questions.mdè¦æ±‚: >30%)
	if lastRanking.BSRRank != nil && *lastRanking.BSRRank > 0 && newData.BSR > 0 {
		oldBSR := float64(*lastRanking.BSRRank)
		newBSR := float64(newData.BSR)
		bsrChangePercentage := math.Abs((newBSR-oldBSR)/oldBSR) * 100
		threshold := trackedProduct.BSRChangeThreshold
		if threshold == 0 {
			threshold = 30.0 // é»˜è®¤é˜ˆå€¼
		}

		if bsrChangePercentage > threshold {
			thresholdPtr := &threshold
			severity := getSeverityForBSRChange(bsrChangePercentage)
			anomalyEvent := models.AnomalyEvent{
				ProductID:        payload.ProductID,
				ASIN:             payload.ASIN,
				EventType:        "bsr_change",
				OldValue:         &oldBSR,
				NewValue:         &newBSR,
				ChangePercentage: &bsrChangePercentage,
				Threshold:        thresholdPtr,
				Severity:         severity,
				CreatedAt:        now,
			}
			anomalyEvents = append(anomalyEvents, anomalyEvent)
		}
	}


	// 3. æ‰¹é‡ä¿å­˜å¼‚å¸¸äº‹ä»¶
	if len(anomalyEvents) > 0 {
		if err := p.db.Create(&anomalyEvents).Error; err != nil {
			p.logger.LogBusinessOperation(ctx, "anomaly_record_failed", "apify_worker", payload.ProductID, "failed",
				"error", err.Error(),
				"events_count", len(anomalyEvents),
			)
		} else {
			p.logger.LogBusinessOperation(ctx, "anomaly_detected", "apify_worker", payload.ProductID, "success",
				"asin", payload.ASIN,
				"events_count", len(anomalyEvents),
				"events", getEventSummary(anomalyEvents),
			)
		}
	}
}

// getSeverityForPriceChange æ ¹æ®ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”ç¡®å®šä¸¥é‡ç¨‹åº¦
func getSeverityForPriceChange(percentage float64) string {
	if percentage >= 20 {
		return "critical"
	} else if percentage >= 10 {
		return "warning"
	}
	return "info"
}

// getSeverityForBSRChange æ ¹æ®BSRå˜åŒ–ç™¾åˆ†æ¯”ç¡®å®šä¸¥é‡ç¨‹åº¦
func getSeverityForBSRChange(percentage float64) string {
	if percentage >= 50 {
		return "critical"
	} else if percentage >= 30 {
		return "warning"
	}
	return "info"
}

// getEventSummary è·å–äº‹ä»¶æ‘˜è¦ç”¨äºæ—¥å¿—
func getEventSummary(events []models.AnomalyEvent) string {
	summary := make([]string, len(events))
	for i, event := range events {
		summary[i] = fmt.Sprintf("%s:%.1f%%", event.EventType, *event.ChangePercentage)
	}
	return strings.Join(summary, ",")
}

// invalidateProductCache æ¸…ç†äº§å“ç›¸å…³ç¼“å­˜ï¼ˆä½¿ç”¨ç»Ÿä¸€ç¼“å­˜keyï¼‰
func (p *ApifyTaskProcessor) invalidateProductCache(ctx context.Context, asin, productID, userID string) {
	// ä½¿ç”¨ç»Ÿä¸€çš„ç¼“å­˜keyæ¸…ç†äº§å“æ•°æ®ç¼“å­˜
	productDataKey := cache.ProductDataKey(productID)
	if err := p.redisClient.Del(ctx, productDataKey).Err(); err != nil {
		p.logger.Error(ctx, "Failed to delete product data cache", "key", productDataKey, "error", err)
	}

	// æ¸…ç†ä»·æ ¼ç¼“å­˜
	priceCacheKey := cache.PriceCacheKey(productID)
	if err := p.redisClient.Del(ctx, priceCacheKey).Err(); err != nil {
		p.logger.Error(ctx, "Failed to delete price cache", "key", priceCacheKey, "error", err)
	}

	// æ¸…ç†æ’åç¼“å­˜
	rankingCacheKey := cache.RankingCacheKey(productID)
	if err := p.redisClient.Del(ctx, rankingCacheKey).Err(); err != nil {
		p.logger.Error(ctx, "Failed to delete ranking cache", "key", rankingCacheKey, "error", err)
	}

	p.logger.Info(ctx, "Invalidated product cache",
		"product_id", productID,
		"asin", asin,
		"initiator_user_id", userID)

	p.logger.LogBusinessOperation(ctx, "cache_invalidated", "apify_worker", productID, "success",
		"asin", asin,
		"initiator_user_id", userID,
	)
}

// HandleGenerateReport å¤„ç†å¼‚æ­¥æŠ¥å‘Šç”Ÿæˆä»»åŠ¡
func (p *ApifyTaskProcessor) HandleGenerateReport(ctx context.Context, t *asynq.Task) error {
	// è§£æä»»åŠ¡è½½è·
	var payload GenerateReportPayload
	if err := json.Unmarshal(t.Payload(), &payload); err != nil {
		p.logger.Error(ctx, "Failed to unmarshal generate report payload", "error", err)
		return fmt.Errorf("failed to unmarshal payload: %w", err)
	}

	p.logger.Info(ctx, "Starting async report generation",
		"analysis_id", payload.AnalysisID,
		"task_id", payload.TaskID,
		"user_id", payload.UserID,
		"force", payload.Force,
	)

	// æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
	if err := p.updateReportStatus(ctx, payload.TaskID, "processing", nil, nil); err != nil {
		p.logger.Error(ctx, "Failed to update status to processing", "task_id", payload.TaskID, "error", err)
		return err
	}

	// æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆé€»è¾‘ï¼ˆå¤ç”¨åŒæ­¥ç‰ˆæœ¬çš„é€»è¾‘ï¼‰
	if err := p.generateReportAsync(ctx, payload); err != nil {
		// æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
		errorMsg := err.Error()
		if updateErr := p.updateReportStatus(ctx, payload.TaskID, "failed", nil, &errorMsg); updateErr != nil {
			p.logger.Error(ctx, "Failed to update failed status", "task_id", payload.TaskID, "error", updateErr)
		}

		p.logger.Error(ctx, "Async report generation failed",
			"analysis_id", payload.AnalysisID,
			"task_id", payload.TaskID,
			"error", err,
		)
		return err
	}

	p.logger.Info(ctx, "Async report generation completed successfully",
		"analysis_id", payload.AnalysisID,
		"task_id", payload.TaskID,
		"user_id", payload.UserID,
	)

	return nil
}

// updateReportStatus æ›´æ–°æŠ¥å‘Šç”ŸæˆçŠ¶æ€
func (p *ApifyTaskProcessor) updateReportStatus(ctx context.Context, taskID, status string, completedAt *time.Time, errorMsg *string) error {
	updates := map[string]interface{}{
		"status": status,
	}

	if completedAt != nil {
		updates["completed_at"] = *completedAt
	}

	if errorMsg != nil {
		updates["error_message"] = *errorMsg
	}

	return p.db.Model(&models.CompetitorAnalysisResult{}).
		Where("task_id = ?", taskID).
		Updates(updates).Error
}

// generateReportAsync å¼‚æ­¥æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆçš„æ ¸å¿ƒé€»è¾‘
func (p *ApifyTaskProcessor) generateReportAsync(ctx context.Context, payload GenerateReportPayload) error {
	// 1. è·å–åˆ†æç»„æ•°æ®
	var analysisGroup models.CompetitorAnalysisGroup
	err := p.db.Where("id = ?", payload.AnalysisID).
		Preload("MainProduct").
		Preload("Competitors.Product").
		First(&analysisGroup).Error
	if err != nil {
		return fmt.Errorf("failed to fetch analysis group: %w", err)
	}

	// 2. è·å–OpenAI API Key
	openaiKey := os.Getenv("OPENAI_API_KEY")
	if openaiKey == "" {
		return fmt.Errorf("OpenAI API key not configured")
	}

	// 3. è·å–ä¸»äº§å“çš„æœ€æ–°æ•°æ®
	mainProductData, err := p.getLatestProductDataForReport(analysisGroup.MainProduct.ID)
	if err != nil {
		return fmt.Errorf("failed to fetch main product data: %w", err)
	}

	// 4. å‡†å¤‡åˆ†ææ•°æ®
	analysisData := llm.CompetitorAnalysisData{
		MainProduct: llm.ProductData{
			ASIN:        analysisGroup.MainProduct.ASIN,
			Title:       p.getStringValue(analysisGroup.MainProduct.Title),
			Price:       mainProductData.Price,
			Currency:    mainProductData.Currency,
			BSR:         mainProductData.BSR,
			Rating:      mainProductData.Rating,
			ReviewCount: mainProductData.ReviewCount,
		},
		Competitors:     make([]llm.ProductData, len(analysisGroup.Competitors)),
		AnalysisMetrics: []string{"price", "bsr", "rating", "features"},
	}

	// 5. è·å–ç«å“æ•°æ®
	for i, comp := range analysisGroup.Competitors {
		competitorData, err := p.getLatestProductDataForReport(comp.Product.ID)
		if err != nil {
			p.logger.Error(ctx, "Failed to get competitor data", "asin", comp.Product.ASIN, "error", err)
			// ä½¿ç”¨é»˜è®¤æ•°æ®ç»§ç»­å¤„ç†
			competitorData = &ProductDataForReport{
				Price: 0, Currency: "USD", BSR: 0, Rating: 0, ReviewCount: 0,
			}
		}

		analysisData.Competitors[i] = llm.ProductData{
			ASIN:        comp.Product.ASIN,
			Title:       p.getStringValue(comp.Product.Title),
			Price:       competitorData.Price,
			Currency:    competitorData.Currency,
			BSR:         competitorData.BSR,
			Rating:      competitorData.Rating,
			ReviewCount: competitorData.ReviewCount,
		}
	}

	// 6. è°ƒç”¨DeepSeekç”ŸæˆæŠ¥å‘Š
	client := llm.NewDeepSeekClient(openaiKey)
	report, err := client.GenerateCompetitorReport(ctx, analysisData)
	if err != nil {
		return fmt.Errorf("failed to generate LLM report: %w", err)
	}

	// 7. ä¿å­˜åˆ†æç»“æœ
	analysisDataJSON, _ := json.Marshal(analysisData)
	insightsJSON, _ := json.Marshal(report)
	recommendationsJSON, _ := json.Marshal(report.Recommendations)
	completedAt := time.Now()

	err = p.updateReportStatus(ctx, payload.TaskID, "completed", &completedAt, nil)
	if err != nil {
		return fmt.Errorf("failed to save final result: %w", err)
	}

	// 8. æ›´æ–°å®Œæ•´çš„åˆ†æç»“æœ
	updates := map[string]interface{}{
		"analysis_data":   analysisDataJSON,
		"insights":        insightsJSON,
		"recommendations": recommendationsJSON,
	}

	err = p.db.Model(&models.CompetitorAnalysisResult{}).
		Where("task_id = ?", payload.TaskID).
		Updates(updates).Error
	if err != nil {
		return fmt.Errorf("failed to update analysis data: %w", err)
	}

	p.logger.LogBusinessOperation(ctx, "generate_report_async_completed", "analysis_group", payload.AnalysisID, "success",
		"task_id", payload.TaskID,
		"competitor_count", len(analysisGroup.Competitors),
		"has_recommendations", len(report.Recommendations),
	)

	return nil
}

// ProductDataForReport äº§å“æ•°æ®ç»“æ„ï¼ˆé¿å…ä¸å…¶ä»–åœ°æ–¹å†²çªï¼‰
type ProductDataForReport struct {
	Price       float64
	Currency    string
	BSR         int
	Rating      float64
	ReviewCount int
}

// getLatestProductDataForReport è·å–äº§å“çš„æœ€æ–°æ•°æ®
func (p *ApifyTaskProcessor) getLatestProductDataForReport(productID string) (*ProductDataForReport, error) {
	// è·å–æœ€æ–°ä»·æ ¼æ•°æ®
	var latestPrice models.PriceHistory
	err := p.db.Where("product_id = ?", productID).
		Order("recorded_at DESC").
		First(&latestPrice).Error
	if err != nil && err != gorm.ErrRecordNotFound {
		return nil, err
	}

	// è·å–æœ€æ–°æ’åæ•°æ®
	var latestRanking models.RankingHistory
	err = p.db.Where("product_id = ?", productID).
		Order("recorded_at DESC").
		First(&latestRanking).Error
	if err != nil && err != gorm.ErrRecordNotFound {
		return nil, err
	}

	data := &ProductDataForReport{
		Price:       latestPrice.Price,
		Currency:    latestPrice.Currency,
		ReviewCount: latestRanking.ReviewCount,
	}

	// å®‰å…¨è®¾ç½®BSRå’ŒRating
	if latestRanking.BSRRank != nil {
		data.BSR = *latestRanking.BSRRank
	}
	if latestRanking.Rating != nil {
		data.Rating = *latestRanking.Rating
	}

	return data, nil
}

// getStringValue å®‰å…¨è·å–å­—ç¬¦ä¸²æŒ‡é’ˆçš„å€¼
func (p *ApifyTaskProcessor) getStringValue(str *string) string {
	if str != nil {
		return *str
	}
	return ""
}
