package scheduler

import (
	"context"
	"log/slog"
	"time"

	"amazonpilot/internal/pkg/logger"
	"amazonpilot/internal/pkg/models"
	"amazonpilot/internal/pkg/queue"

	"gorm.io/gorm"
)

// SchedulerService è°ƒåº¦å™¨æœåŠ¡
type SchedulerService struct {
	db          *gorm.DB
	queueMgr    *queue.QueueManager
	logger      *logger.ServiceLogger
	ctx         context.Context
	cancelFunc  context.CancelFunc
}

// NewSchedulerService åˆ›å»ºè°ƒåº¦å™¨æœåŠ¡
func NewSchedulerService(db *gorm.DB, queueMgr *queue.QueueManager) *SchedulerService {
	ctx, cancel := context.WithCancel(context.Background())
	
	return &SchedulerService{
		db:         db,
		queueMgr:   queueMgr,
		logger:     logger.NewServiceLogger("scheduler"),
		ctx:        ctx,
		cancelFunc: cancel,
	}
}

// Start å¯åŠ¨è°ƒåº¦å™¨
func (ss *SchedulerService) Start() error {
	slog.Info("Starting scheduler service")

	// è®¾ç½®å‘¨æœŸæ€§ä»»åŠ¡
	if err := ss.setupPeriodicTasks(); err != nil {
		return err
	}

	// å¯åŠ¨è°ƒåº¦å™¨
	if err := ss.queueMgr.Start(); err != nil {
		return err
	}

	// å¯åŠ¨åå°ä»»åŠ¡è°ƒåº¦
	go ss.runPeriodicScheduler()

	slog.Info("Scheduler service started successfully")
	return nil
}

// setupPeriodicTasks è®¾ç½®å‘¨æœŸæ€§ä»»åŠ¡
func (ss *SchedulerService) setupPeriodicTasks() error {
	// æ¯å°æ—¶æ›´æ–°æ´»è·ƒäº§å“ä»·æ ¼
	hourlyProductUpdate := queue.TaskPayload{
		TaskType:  queue.TaskTypeUpdateProduct,
		Priority:  5,
		Metadata: map[string]interface{}{
			"batch_update": true,
			"frequency":   "hourly",
		},
	}
	
	if err := ss.queueMgr.SchedulePeriodicTask("0 * * * *", queue.TaskTypeUpdateProduct, hourlyProductUpdate); err != nil {
		return err
	}

	// æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ•°æ®æ¸…ç†
	dailyCleanup := queue.TaskPayload{
		TaskType: queue.TaskTypeDataCleanup,
		Priority: 2,
		Metadata: map[string]interface{}{
			"cleanup_type": "daily",
		},
	}
	
	if err := ss.queueMgr.SchedulePeriodicTask("0 2 * * *", queue.TaskTypeDataCleanup, dailyCleanup); err != nil {
		return err
	}

	// ğŸš« ç§»é™¤å¼‚å¸¸æ£€æµ‹å®šæ—¶ä»»åŠ¡ - æ”¹ä¸ºæ•°æ®é©±åŠ¨æ¨¡å¼
	// å¼‚å¸¸æ£€æµ‹ç°åœ¨ç”±æ•°æ®æ›´æ–°æ—¶è‡ªåŠ¨è§¦å‘ï¼Œæ— éœ€å®šæ—¶æ‰«æ
	// å½“Apify Workerä¿å­˜æ•°æ®åä¼šç«‹å³æ£€æµ‹å¹¶å‘é€Redisæ¶ˆæ¯

	// æ¯å¤©æ—©ä¸Š8ç‚¹è§¦å‘ç«äº‰å¯¹æ‰‹åˆ†æ (å¯¹è®¾ç½®ä¸ºdailyçš„åˆ†æç»„)
	dailyCompetitorAnalysis := queue.TaskPayload{
		TaskType: queue.TaskTypeCompetitorAnalysis,
		Priority: 6,
		Metadata: map[string]interface{}{
			"frequency": "daily",
			"auto_trigger": true,
		},
	}
	
	if err := ss.queueMgr.SchedulePeriodicTask("0 8 * * *", queue.TaskTypeCompetitorAnalysis, dailyCompetitorAnalysis); err != nil {
		return err
	}

	slog.Info("Periodic tasks scheduled successfully")
	return nil
}

// runPeriodicScheduler è¿è¡Œå‘¨æœŸæ€§è°ƒåº¦å™¨
func (ss *SchedulerService) runPeriodicScheduler() {
	ticker := time.NewTicker(10 * time.Minute) // æ¯10åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
	defer ticker.Stop()

	for {
		select {
		case <-ss.ctx.Done():
			slog.Info("Scheduler stopped")
			return
		case <-ticker.C:
			ss.checkAndScheduleTasks()
		}
	}
}

// checkAndScheduleTasks æ£€æŸ¥å¹¶è°ƒåº¦ä»»åŠ¡
func (ss *SchedulerService) checkAndScheduleTasks() {
	// æ£€æŸ¥éœ€è¦æ›´æ–°çš„äº§å“
	ss.scheduleProductUpdates()
	
	// æ£€æŸ¥éœ€è¦åˆ†æçš„ç«äº‰å¯¹æ‰‹ç»„
	ss.scheduleCompetitorAnalyses()
	
	// æ£€æŸ¥éœ€è¦å¤„ç†çš„ä¼˜åŒ–åˆ†æ
	ss.scheduleOptimizationAnalyses()
}

// scheduleProductUpdates è°ƒåº¦äº§å“æ›´æ–°ä»»åŠ¡
func (ss *SchedulerService) scheduleProductUpdates() {
	// æŸ¥æ‰¾éœ€è¦æ›´æ–°çš„äº§å“ (è¶…è¿‡2å°æ—¶æœªæ›´æ–°çš„æ´»è·ƒäº§å“)
	var products []models.Product
	twoHoursAgo := time.Now().Add(-2 * time.Hour)
	
	err := ss.db.Where("is_tracked = ? AND updated_at < ?", true, twoHoursAgo).
		Limit(50). // æ‰¹é‡å¤„ç†ï¼Œé¿å…è¿‡è½½
		Find(&products).Error
	
	if err != nil {
		ss.logger.LogError(ss.ctx, "Failed to query products for update", "error", err.Error())
		return
	}

	for _, product := range products {
		if err := ss.queueMgr.EnqueueProductUpdate(product.ID, product.UserID, 5); err != nil {
			ss.logger.LogError(ss.ctx, "Failed to enqueue product update",
				"product_id", product.ID,
				"error", err.Error(),
			)
		}
	}

	if len(products) > 0 {
		slog.Info("Scheduled product updates", "count", len(products))
	}
}

// scheduleCompetitorAnalyses è°ƒåº¦ç«äº‰å¯¹æ‰‹åˆ†æä»»åŠ¡
func (ss *SchedulerService) scheduleCompetitorAnalyses() {
	// æŸ¥æ‰¾éœ€è¦åˆ†æçš„ç«äº‰å¯¹æ‰‹ç»„ (daily frequencyä¸”è¶…è¿‡20å°æ—¶æœªåˆ†æ)
	var analysisGroups []models.CompetitorAnalysisGroup
	twentyHoursAgo := time.Now().Add(-20 * time.Hour)
	
	err := ss.db.Where("is_active = ? AND update_frequency = ? AND (last_analysis_at IS NULL OR last_analysis_at < ?)", 
		true, "daily", twentyHoursAgo).
		Limit(20).
		Find(&analysisGroups).Error
	
	if err != nil {
		ss.logger.LogError(ss.ctx, "Failed to query analysis groups", "error", err.Error())
		return
	}

	for _, group := range analysisGroups {
		if err := ss.queueMgr.EnqueueCompetitorAnalysis(group.ID, group.UserID, 6); err != nil {
			ss.logger.LogError(ss.ctx, "Failed to enqueue competitor analysis",
				"analysis_id", group.ID,
				"error", err.Error(),
			)
		}
	}

	if len(analysisGroups) > 0 {
		slog.Info("Scheduled competitor analyses", "count", len(analysisGroups))
	}
}

// scheduleOptimizationAnalyses è°ƒåº¦ä¼˜åŒ–åˆ†æä»»åŠ¡
func (ss *SchedulerService) scheduleOptimizationAnalyses() {
	// æŸ¥æ‰¾pendingçŠ¶æ€çš„ä¼˜åŒ–åˆ†æ (åˆ›å»ºè¶…è¿‡5åˆ†é’Ÿä½†æœªå¼€å§‹å¤„ç†)
	var analyses []models.OptimizationAnalysis
	fiveMinutesAgo := time.Now().Add(-5 * time.Minute)
	
	err := ss.db.Where("status = ? AND started_at < ?", "pending", fiveMinutesAgo).
		Limit(10).
		Find(&analyses).Error
	
	if err != nil {
		ss.logger.LogError(ss.ctx, "Failed to query optimization analyses", "error", err.Error())
		return
	}

	for _, analysis := range analyses {
		if err := ss.queueMgr.EnqueueOptimizationAnalysis(analysis.ID, analysis.ProductID, analysis.UserID, 7); err != nil {
			ss.logger.LogError(ss.ctx, "Failed to enqueue optimization analysis",
				"analysis_id", analysis.ID,
				"error", err.Error(),
			)
		}
	}

	if len(analyses) > 0 {
		slog.Info("Scheduled optimization analyses", "count", len(analyses))
	}
}

// Stop åœæ­¢è°ƒåº¦å™¨
func (ss *SchedulerService) Stop() {
	ss.cancelFunc()
	slog.Info("Scheduler service stopped")
}